{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/work/multi_doc_analyzer\")\n",
    "sys.path.append(\"/work/relation_extraction/Bert_model/data/\")\n",
    "\n",
    "import torch as T\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda\n",
    "from allennlp.nn import util as nn_util\n",
    "from multi_doc_analyzer.structure.structure import *\n",
    "from multi_doc_analyzer.tokenization.tokenizer import MDATokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.data.tokenizers import Token, Tokenizer, WordTokenizer\n",
    "from allennlp.data.token_indexers import TokenIndexer\n",
    "\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.fields import TextField, LabelField, ArrayField\n",
    "\n",
    "from ace05_set_reader import ACE05Reader\n",
    "\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.data.iterators import BucketIterator, DataIterator, BasicIterator\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder\n",
    "import random\n",
    "\n",
    "from allennlp.data.token_indexers import PretrainedBertIndexer\n",
    "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders.bert_token_embedder import PretrainedBertEmbedder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/work/LDC2006T06/dataset/dev/\"\n",
    "test_path = \"/work/LDC2006T06/dataset/test/\"\n",
    "model_folder = \"/work/model_checkpoint/bert_model_checkpoint/\"\n",
    "output_path = \"/work/relation_extraction/Bert_model/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "        \n",
    "config = Config(\n",
    "    seed=1,\n",
    "    batch_size=64,\n",
    "    lr=3e-4,                # learning rate\n",
    "    epochs=50,\n",
    "    hidden_sz=128,\n",
    "    arg_sz=3,\n",
    "    max_seq_len=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_GPU = T.cuda.is_available()\n",
    "USE_GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0cc895d930>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seed for both CPU and CUDA\n",
    "T.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_type2idx = {'X':0, 'O': 1, 'PER': 2, 'ORG': 3, 'LOC': 4, 'GPE': 5, 'FAC': 6, 'VEH': 7, 'WEA': 8}\n",
    "\n",
    "r_label2idx = {'PHYS-lr': 1, 'PART-WHOLE-lr': 2, 'PER-SOC-lr': 3, 'ORG-AFF-lr': 4, 'ART-lr': 5, 'GEN-AFF-lr': 6,\n",
    "               'PHYS-rl': 7, 'PART-WHOLE-rl': 8, 'PER-SOC-rl': 9, 'ORG-AFF-rl': 10, 'ART-rl': 11, 'GEN-AFF-rl': 12,\n",
    "               'NONE': 0}\n",
    "\n",
    "r_idx2label = {v: k for k, v in r_label2idx.items()}\n",
    "\n",
    "class RelationDatasetReader(DatasetReader):\n",
    "    \"\"\"\n",
    "    Reads Structure object formatted datasets files, and creates AllenNLP instances.\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer: Tokenizer=None, token_indexers: Dict[str, TokenIndexer]=None, \n",
    "                 MAX_WORDPIECES: int=config.max_seq_len, \n",
    "                 is_training = False, ace05_reader: ACE05Reader=None):\n",
    "        # make sure results may be reproduced when sampling...\n",
    "        super().__init__(lazy=False)\n",
    "        random.seed(0)\n",
    "        self.is_training = is_training\n",
    "        self.ace05_reader = ace05_reader\n",
    "        \n",
    "        # NOTE AllenNLP automatically adds [CLS] and [SEP] word peices in the begining and end of the context,\n",
    "        # therefore we need to subtract 2\n",
    "        self.MAX_WORDPIECES = MAX_WORDPIECES - 2\n",
    "        \n",
    "        self.tokenizer = tokenizer or WordTokenizer()\n",
    "        \n",
    "        # BERT specific init\n",
    "        self._token_indexers = token_indexers\n",
    "\n",
    "    def text_to_instance(self, sentence: Sentence) -> Instance:\n",
    "#         sentence_tokens = [Token(x) for x in self.tokenizer(sentence.text)]\n",
    "#         sentence_tokens = [Token(i) for t in sentence.text for i in self.tokenizer(t)]\n",
    "#         sentence_tokens = [Token(text=t) for t in sentence.text]\n",
    "        sentence_tokens = []\n",
    "#         td = self.tokenizer(sentence.text)\n",
    "#         print(td)\n",
    "        for t in sentence.tokens:\n",
    "#             print(type(t.text), t.text)\n",
    "            sentence_tokens.append(Token(text=t.text))\n",
    "#         for t in sentence.text:\n",
    "#             td = self.tokenizer(t)\n",
    "#             assert len(td) == 1 or len(td) == 0\n",
    "#             if td:\n",
    "#                 sentence_tokens.append(Token(text=td[0]))\n",
    "#             else:\n",
    "#                 sentence_tokens.append(Token(text='[MASK]'))\n",
    "\n",
    "        sentence_field = TextField(sentence_tokens, self._token_indexers)\n",
    "        fields = {\"tokens\": sentence_field}\n",
    "#         char_list_field = ListField([t for t in sentence.text])\n",
    "#         fields['char_list'] = char_list_field\n",
    "\n",
    "        e_tuple_check_dicts = {} # {(train_arg_l.id, train_arg_r.id):true_label, ...}\n",
    "        if self.is_training: \n",
    "            for r in sentence.relation_mentions:\n",
    "                train_arg_l, train_arg_r, true_label = r.get_left_right_args()\n",
    "                e_tuple_check_dicts[(train_arg_l.id, train_arg_r.id)] = true_label\n",
    "\n",
    "        # construct pair entities\n",
    "        for arg_left_idx in range(len(sentence.entity_mentions)-1):\n",
    "            for arg_right_idx in range(arg_left_idx+1, len(sentence.entity_mentions)):\n",
    "                arg_left = sentence.entity_mentions[arg_left_idx]\n",
    "                arg_right = sentence.entity_mentions[arg_right_idx]\n",
    "                arg_vec = T.zeros(self.MAX_WORDPIECES + 2, dtype=T.long)\n",
    "                arg_vec[:len(sentence_tokens)+2] = 1\n",
    "\n",
    "                # +1 because the first token is [CLS]\n",
    "                arg_vec[arg_left.char_b+1:arg_left.char_e+1] = e_type2idx[arg_left.type]\n",
    "                arg_vec[arg_right.char_b+1:arg_right.char_e+1] = e_type2idx[arg_right.type]\n",
    "                fields[\"arg_idx\"] = ArrayField(arg_vec)\n",
    "\n",
    "\n",
    "#                 fields[\"arg_left\"] = SpanField(arg_left.char_b, arg_left.char_e, char_list_field)\n",
    "#                 fields[\"arg_right\"] = SpanField(arg_right.char_b, arg_right.char_e, char_list_field)\n",
    "                if self.is_training:\n",
    "                    if (arg_left.id, arg_right.id) in e_tuple_check_dicts.keys():\n",
    "                        fields[\"label\"] = LabelField(r_label2idx[e_tuple_check_dicts[(arg_left.id, arg_right.id)]], skip_indexing=True)\n",
    "                    else:\n",
    "                        fields[\"label\"] = LabelField(r_label2idx['NONE'], skip_indexing=True)\n",
    "                yield Instance(fields)\n",
    "    \n",
    "    def _read(self, file_path: str)->Iterator: \n",
    "        doc_dicts = self.ace05_reader.read(file_path)\n",
    "        tokenizer = MDATokenizer('bert-en')\n",
    "        for doc in doc_dicts.values():\n",
    "            tokenizer.annotate_document(doc)\n",
    "            for s in doc.sentences: \n",
    "                if len(s.text) <= config.max_seq_len:\n",
    "                    for instance in self.text_to_instance(s):\n",
    "                        yield instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(Model):\n",
    "    def __init__(self, word_embeddings: TextFieldEmbedder,\n",
    "                out_sz: int=len(r_label2idx)):\n",
    "        super().__init__(vocab)\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self._entity_embeddings = T.nn.Embedding(num_embeddings=len(e_type2idx), embedding_dim=config.arg_sz, padding_idx=0)\n",
    "        self.gru = T.nn.GRU(word_embeddings.get_output_dim()+config.arg_sz, config.hidden_sz, batch_first=True)\n",
    "        self.projection = nn.Linear(config.hidden_sz, out_sz)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, tokens: Dict[str, T.tensor], arg_idx: T.tensor, label: T.tensor = None) -> Dict[str, T.tensor]:\n",
    "        mask = get_text_field_mask(tokens)\n",
    "        \n",
    "        embeddings = self.word_embeddings(tokens)\n",
    "        pad_len = embeddings.shape[-2]\n",
    "        \n",
    "        arg_idx = arg_idx[:,:pad_len]\n",
    "        arg_idx = arg_idx.type(T.long)\n",
    "        \n",
    "        arg_emb = self._entity_embeddings(arg_idx)\n",
    "\n",
    "        concat = T.cat((embeddings, arg_emb), -1)\n",
    "        ot, ht = self.gru(concat, None) # revise this \"None\"\n",
    "        ot = ot[:,-1,:]    \n",
    "        class_logits = self.projection(ot)\n",
    "        \n",
    "        output = {\"class_logits\": class_logits}\n",
    "        output[\"loss\"] = self.loss(class_logits, label)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit # the sigmoid function\n",
    "def tonp(tsr): return tsr.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "class Predictor:\n",
    "    def __init__(self, model: Model, iterator: DataIterator,\n",
    "                 cuda_device: int=-1) -> None:\n",
    "        self.model = model\n",
    "        self.iterator = iterator\n",
    "        self.cuda_device = cuda_device\n",
    "        \n",
    "    def _extract_data(self, batch) -> np.ndarray:\n",
    "        out_dict = self.model(**batch)\n",
    "        return expit(tonp(out_dict[\"class_logits\"]))\n",
    "    \n",
    "    def predict(self, ds: Iterable[Instance]) -> np.ndarray:\n",
    "        pred_generator = self.iterator(ds, num_epochs=1, shuffle=False)\n",
    "        self.model.eval()\n",
    "        pred_generator_tqdm = tqdm(pred_generator, total=self.iterator.get_num_batches(ds))\n",
    "        preds = []\n",
    "        with T.no_grad():\n",
    "            for batch in pred_generator_tqdm:\n",
    "                batch = nn_util.move_to_device(batch, self.cuda_device)\n",
    "                preds.append(self._extract_data(batch))\n",
    "        return np.concatenate(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comfusion_matrix(label_classes, predict_classes, out_folder):\n",
    "\tlabel_types = list(r_idx2label.values())\n",
    "\n",
    "\tcm = confusion_matrix(label_classes, predict_classes, label_types)\n",
    "\tprint(cm)\n",
    "\tfig = plt.figure()\n",
    "\tax = fig.add_subplot(111)\n",
    "\tcax = ax.matshow(cm)\n",
    "\tfor (i, j), z in np.ndenumerate(cm):\n",
    "\t\tax.text(j, i, '{:0.0f}'.format(z), ha='center', va='center', color='white')\n",
    "\tfig.colorbar(cax)\n",
    "\tax.set_xticklabels([''] + label_types)\n",
    "\tax.set_yticklabels([''] + label_types)\n",
    "\tplt.xlabel('Predicted')\n",
    "\tplt.ylabel('True')\n",
    "\t\n",
    "\tplt.savefig(out_folder + 'confusion_matrix.png')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█▏        | 9/80 [00:00<00:00, 86.96it/s]\u001b[A\n",
      " 31%|███▏      | 25/80 [00:00<00:00, 99.70it/s]\u001b[A\n",
      " 52%|█████▎    | 42/80 [00:00<00:00, 112.72it/s]\u001b[A\n",
      " 71%|███████▏  | 57/80 [00:00<00:00, 120.72it/s]\u001b[A\n",
      " 85%|████████▌ | 68/80 [00:00<00:00, 116.37it/s]\u001b[A\n",
      " 99%|█████████▉| 79/80 [00:00<00:00, 107.20it/s]\u001b[A\n",
      "2394it [00:09, 252.85it/s]:00<00:00, 123.64it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    ace05_reader = ACE05Reader(lang='en')\n",
    "    \n",
    "    token_indexer = PretrainedBertIndexer(\n",
    "        pretrained_model=\"bert-base-uncased\",\n",
    "        max_pieces=config.max_seq_len\n",
    "#         truncate_long_sequences=False,\n",
    "#         do_lowercase=False               # for cased condition\n",
    "    )\n",
    " \n",
    "\t# AllenNLP DatasetReader\n",
    "    reader = RelationDatasetReader(\n",
    "        is_training=True, \n",
    "        ace05_reader=ace05_reader, \n",
    "        tokenizer=lambda s: token_indexer.wordpiece_tokenizer(s),\n",
    "        token_indexers={\"tokens\": token_indexer}\n",
    "    )\n",
    "\n",
    "    train_ds = reader.read(train_path)\n",
    "    \n",
    "    vocab = Vocabulary()\n",
    "    iterator = BucketIterator(batch_size=config.batch_size, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
    "    iterator.index_with(vocab)\n",
    "\n",
    "    bert_embedder = PretrainedBertEmbedder(\n",
    "        pretrained_model=\"bert-base-uncased\",\n",
    "        top_layer_only=True, # conserve memory   \n",
    "    )\n",
    "    word_embeddings: TextFieldEmbedder = BasicTextFieldEmbedder({\"tokens\": bert_embedder},\n",
    "                                                                # we'll be ignoring masks so we'll need to set this to True\n",
    "                                                               allow_unmatched_keys = True)\n",
    "    model = BERT(word_embeddings)\n",
    "    if USE_GPU:\n",
    "        model.cuda()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # training\n",
    "    from allennlp.training.trainer import Trainer\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        iterator=iterator,\n",
    "        train_dataset=train_ds,\n",
    "        cuda_device=0 if USE_GPU else -1,\n",
    "        num_epochs=config.epochs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 1.0487 ||: 100%|██████████| 38/38 [00:02<00:00, 16.13it/s]\n",
      "loss: 0.6365 ||: 100%|██████████| 38/38 [00:01<00:00, 19.07it/s]\n",
      "loss: 0.5911 ||: 100%|██████████| 38/38 [00:02<00:00, 18.67it/s]\n",
      "loss: 0.5415 ||: 100%|██████████| 38/38 [00:01<00:00, 19.09it/s]\n",
      "loss: 0.4828 ||: 100%|██████████| 38/38 [00:01<00:00, 21.63it/s]\n",
      "loss: 0.4091 ||: 100%|██████████| 38/38 [00:02<00:00, 18.18it/s]\n",
      "loss: 0.3348 ||: 100%|██████████| 38/38 [00:02<00:00, 18.64it/s]\n",
      "loss: 0.2616 ||: 100%|██████████| 38/38 [00:02<00:00, 17.97it/s]\n",
      "loss: 0.2064 ||: 100%|██████████| 38/38 [00:02<00:00, 19.30it/s]\n",
      "loss: 0.1719 ||: 100%|██████████| 38/38 [00:02<00:00, 19.52it/s]\n",
      "loss: 0.1432 ||: 100%|██████████| 38/38 [00:02<00:00, 17.72it/s]\n",
      "loss: 0.1173 ||: 100%|██████████| 38/38 [00:02<00:00, 18.31it/s]\n",
      "loss: 0.0962 ||: 100%|██████████| 38/38 [00:01<00:00, 19.28it/s]\n",
      "loss: 0.0810 ||: 100%|██████████| 38/38 [00:02<00:00, 18.38it/s]\n",
      "loss: 0.0744 ||: 100%|██████████| 38/38 [00:02<00:00, 18.67it/s]\n",
      "loss: 0.0557 ||: 100%|██████████| 38/38 [00:01<00:00, 19.12it/s]\n",
      "loss: 0.0508 ||: 100%|██████████| 38/38 [00:02<00:00, 18.90it/s]\n",
      "loss: 0.0483 ||: 100%|██████████| 38/38 [00:02<00:00, 18.79it/s]\n",
      "loss: 0.0368 ||: 100%|██████████| 38/38 [00:02<00:00, 20.39it/s]\n",
      "loss: 0.0324 ||: 100%|██████████| 38/38 [00:02<00:00, 18.76it/s]\n",
      "loss: 0.0287 ||: 100%|██████████| 38/38 [00:01<00:00, 19.02it/s]\n",
      "loss: 0.0261 ||: 100%|██████████| 38/38 [00:02<00:00, 18.76it/s]\n",
      "loss: 0.0224 ||: 100%|██████████| 38/38 [00:01<00:00, 19.14it/s]\n",
      "loss: 0.0194 ||: 100%|██████████| 38/38 [00:02<00:00, 18.08it/s]\n",
      "loss: 0.0164 ||: 100%|██████████| 38/38 [00:02<00:00, 18.42it/s]\n",
      "loss: 0.0172 ||: 100%|██████████| 38/38 [00:02<00:00, 18.58it/s]\n",
      "loss: 0.0154 ||: 100%|██████████| 38/38 [00:02<00:00, 19.89it/s]\n",
      "loss: 0.0113 ||: 100%|██████████| 38/38 [00:01<00:00, 19.15it/s]\n",
      "loss: 0.0102 ||: 100%|██████████| 38/38 [00:02<00:00, 18.70it/s]\n",
      "loss: 0.0088 ||: 100%|██████████| 38/38 [00:02<00:00, 18.63it/s]\n",
      "loss: 0.0081 ||: 100%|██████████| 38/38 [00:02<00:00, 18.13it/s]\n",
      "loss: 0.0086 ||: 100%|██████████| 38/38 [00:02<00:00, 19.42it/s]\n",
      "loss: 0.0075 ||: 100%|██████████| 38/38 [00:02<00:00, 18.17it/s]\n",
      "loss: 0.0068 ||: 100%|██████████| 38/38 [00:02<00:00, 19.04it/s]\n",
      "loss: 0.0062 ||: 100%|██████████| 38/38 [00:02<00:00, 17.96it/s]\n",
      "loss: 0.0060 ||: 100%|██████████| 38/38 [00:02<00:00, 18.67it/s]\n",
      "loss: 0.0128 ||: 100%|██████████| 38/38 [00:01<00:00, 19.06it/s]\n",
      "loss: 0.0086 ||: 100%|██████████| 38/38 [00:02<00:00, 18.77it/s]\n",
      "loss: 0.0063 ||: 100%|██████████| 38/38 [00:02<00:00, 18.37it/s]\n",
      "loss: 0.0052 ||: 100%|██████████| 38/38 [00:02<00:00, 19.90it/s]\n",
      "loss: 0.0069 ||: 100%|██████████| 38/38 [00:02<00:00, 17.67it/s]\n",
      "loss: 0.0075 ||: 100%|██████████| 38/38 [00:02<00:00, 18.72it/s]\n",
      "loss: 0.0073 ||: 100%|██████████| 38/38 [00:02<00:00, 18.83it/s]\n",
      "loss: 0.0046 ||: 100%|██████████| 38/38 [00:02<00:00, 19.73it/s]\n",
      "loss: 0.0034 ||: 100%|██████████| 38/38 [00:02<00:00, 18.22it/s]\n",
      "loss: 0.0029 ||: 100%|██████████| 38/38 [00:01<00:00, 19.07it/s]\n",
      "loss: 0.0028 ||: 100%|██████████| 38/38 [00:01<00:00, 19.15it/s]\n",
      "loss: 0.0025 ||: 100%|██████████| 38/38 [00:02<00:00, 18.58it/s]\n",
      "loss: 0.0027 ||: 100%|██████████| 38/38 [00:02<00:00, 18.63it/s]\n",
      "loss: 0.0024 ||: 100%|██████████| 38/38 [00:02<00:00, 17.94it/s]\n"
     ]
    }
   ],
   "source": [
    "    # train the model \n",
    "    metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # load model\n",
    "#     model.load_state_dict(T.load(config.model_folder + \"/model.th\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # save \n",
    "    with open(model_folder+'model.th', 'wb') as f:\n",
    "        T.save(model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:02<00:00, 18.23it/s]\n"
     ]
    }
   ],
   "source": [
    "    # training data analysis\n",
    "    seq_iterator = BasicIterator(batch_size=config.batch_size)\n",
    "    seq_iterator.index_with(vocab)\n",
    "    \n",
    "    predictor = Predictor(model, seq_iterator, cuda_device=0 if USE_GPU else -1)\n",
    "    train_preds = predictor.predict(train_ds) \n",
    "    \n",
    "    label_types = [r_idx2label.get(i.fields['label'].label) for i in train_ds]\n",
    "    predict_types = [r_idx2label.get(i) for i in np.argmax(train_preds, axis=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  70    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0   38    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0   61    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0   38    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    1    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    1    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    1    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0   47    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    3    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0   39    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    6    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    1    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0 2088]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2deZgVxdX/P98ZFlkUF4zyCgZFXAAVBXFPiBpFsxizqMS451WJS9xI1CTKz6jRGJe4YYgi8qpxi0ajRGM0uKOgICpiBFcQF8CoICDMnN8fXReay52ZvjM9UHfmfJ6nnrldXXXqVN+5fbqWPkdmhuM4juMAVK1pBRzHcZx4cKPgOI7jLMeNguM4jrMcNwqO4zjOctwoOI7jOMtxo+A4juMsx43CGkZSjaQpkl6RdJekjiF/QVG5oyRdI+mbkqyozhRJu0naKuSZpJmSRoW6PSUtCuWmSZoh6RBJ+4W8KZIWSHo9fB5b1Pb2kqakjocGeW3D8baSpobP4yUNTJXtGXQq9PNNSfNDW9Ml1aZ0+EDSgyk5r0t6KfTn9VS5s1LyO0q6NchaLOkpSZ3Due6S7pP0Rrgef5S0WSpvlqTZQfYbkr4M7U2X9IdUG+MlnSzp+XBuiqQ7JG1az/f6vaD31kXXovA9FFK78N1+nMob25C8Et/pWElts36nQcbtkp4M38kLkp6VdJCkwZI+LdJzn1DHJF2WknGmpBH1XIf+oc6QovyaIvk9S7T7r6Kyhf/3dyR1Vf2/kWclKeRXS5qsFb+R8UHeawq/kYaQNELSmVnKVjxm5mkNJmBB6vOtwOnF+eH4KOCa8Hkp8NPweRLwbPj8MPBkSP8P2Dbk9wReCZ+rgTnAH4vkjwcG1aFjFTAfWDscXw28WCgPHA9cn5IzMFW3J/AKsADYGHgXGAecDnQFaoBvhbIjgDOL5QCLgUfq0O1s4PJUO1sB7QEBzwPHpvp9Y+j70cBGwDvA34FLgcHhWm4EdACmA7uHuhOD3tuk2v0uMLie7/WOwvdQfC1KlF3+3TYgr6YgL9XfNqFvjwGHlfhOB9YhT8BHwJ9SeV8FTgb2Ah6oo95i4C2gazg+ExhRj96XhOtwc13/96m8waXaZdXfyPzwv7OgqD9Hs+I3cjsrfiOnAn9O/UYOTNXbNsNvtE36f7OlJx8pxMWTwBYZyn0JnC2pL7ApMC3kb0JyUzwWONTMXi6uaGY1wFxgfQBJb0u6BBgA7FOqMTOrJblh7hyyBgDXAruF492ApzPofSIwBrgf2MLM5oa+nFVfJZKb4SZ1nOsGzE7p+jowNOizJXBEyK8B/kZyM7kj6HIzcBhwDNAR+MDMPjSzRcCUVJs9gJvM7LXw9H0Z8FtgWSmFwkhlD8L30EDfGiQlbzFwqKTBwJ2E7z707Xnqvkal2AuoBR4JbbwN/Izkxjq4nnrLgFHAaRn0FvAjEqP3TUlrlaFfXTxJcpMuNPF6GAW9QvifDpzGit/IScAvQ343YFahUKnfSBA8XtKVkiYBP89B74rBjUIkSGoD7A8U/kk7pIfXwPmp4gZcCTxL8g8+KeQ/DawL/BFoJ+nrJdpZi+TGODmVPQ94AfhnPSo+DewmqRPJzWQ8KxuFZ1Jlb03pPS6V3ze0m+5nO2DXUPYEYPsSbXcANkhdj0NS50aT/ODvAb4iqXfI7wPcZmbpa7AZ8AmJ4e0HvGBmn5GMApYbY0nrAb2BJ0JWJ5KRQ+Hzc2a2vZk9VUJXgAOBh8zsP8A8SQNS53ql+nFtKv+QVP7RpeSRfO/zSIxdP2COmW0ZvtOdQ5ms9A2y0swzsx1JRh17Fk3v9EqVuxY4TFKXBtrYDXjLzGaS/L98K3Uu/f99byo/3e6v0sJSv5GlIWstkmuxS8hbfvM2szms+I1cYGbzw6krgMck/UPSaZLWrUf/dmY20Mwuq6dMi8ONwpqnQ7ghTiK5Od0Y8heZWf9CAs5N1yF5Cu1EcrMu1NkEOBy4C/gcuEdS+3CuV2jnQ2BRaKvAHRn0fIbkRz4ImBh+6FtI2hDoHI4LHJbS+4CUznsBlxX3E/gslL0eeCkl51ZJb5FMDeyYuh7L9TWzKcDmwJ9IplEmkjwNTgeWZOhXmj0lvUQy8njYzD4oUaYGOEfSf+qZYx5KMn1B+Ds0dW5mqh8npvLvSOXf1IC8vUmu06ap73SOmU3N2tESrA8cJWliOH4y/f+X/n6DIR0LnNKAzPquQ/r/+6BUfrrdC0Ne8W/k85C/GHjbzLYs8RuBxHhVm9mYlO43AduQ/EYGAxNSv5FisvwuWhxuFNY86R/HyWb2ZdY64e/JZvalpPVJbrq/J/lxrAesTfJEeWmo9z7QC9gAGJiSt7C4AUk3hae1wpP+BGAnYHeSpy9IRimHpo7r1Rm4BrilqJ/VwKt11DmM5Ia/lGQdg7AQOiXclF8PN4u9SOaK5wC3ANsBH5BMc6V5m+S6zAhtDpC0Dsk0zAySG9L2JDef4ZLuCfUWAoUF48Xh2o8COkvqkXqyPSH1PdwQpmSGAwcXFj2zkpL7MrAvcAPJFNdwkpvZFwQDQ/KdDpD03QZkpr/TV0n+DwrMB74HbJhRxStZ8WBSWMwtXIfzJVUDPwDODdfhamCIpLUzyi/oXJ06vN/MTi4qssr/boEw7bmKczcze9/MRpvZgSTTYf1K/L/XK7sl06bhIk6F8EPg38D3zGyppI1JFlJ7kNxItjGzAwAkvQAcRD1z+WZ2dNHx55LeY+U552dJFvGuy6jjtcBzku4xsymSNiCZPvp9PXqYpC+BXSRtbWb3AsunGyTtTrKm0oVkRNGHFWss3SUdYWZjw83lOyRTJj8kMVDPkxiQMSQ32Y0lbWRmX5N0GsmoCOA94BhJhadeSG7QmNl7QP+UPscB/2dmx6fyHgf2ZOXRWb0U5AZ5A8zseEkLzKxHMIQdUmXnKtmRdTbJek1dMpd/p8FIVZMYnLtDdodS9eqQNV/SnSSGYXRY10hfh32BqWa2XyrvZpL/u1V2QtXTTo2kwkNQk1GyC+rR1G9kA2B28f97a8ZHCi2HoSTTJa+EKZCHSYa/+5Uo+y7QXtKeZbbxNNA+3LAgMQqbs/J6Qp2Eed6fAH+WND3UE/Db1JrCBZJmAbsCD4aqHUie+J4OT3MXp8T2Ah4nmU/vRfKUX1hjOQj4kaQ3gP+QTDfsTrL4+RTJTXEQibG4meQpuTA1cT3wNUk9SZ4Y/0ByM+so6WmSKYjbSnRzKCmjFfgrK0+dlEMpeU+w6oaEvwXdMn2nZmYkawd9whRdNxKjXViQLV5T+GEJMZeRrE9l1bsp1yEv9mXl38jwOqYJWy1K/jccx3Ecx0cKjuM4Tgo3Co7jOM5y3Cg4juM4y3Gj4DiO4yzHjUILIGxbXOPEoEcMOkAcesSgA8ShRww6VApuFFoGsfzDx6BHDDpAHHrEoAPEoUcMOlQEbhQcx3Gc5fh7ChVAO61lHao613n+S1tMuwYcUFptbd5qrcJSltCWutzIrB5i0CEWPWLQIRY9sujwOZ/MNbOsbj5WYb9vdLJ582sylX1h6pKHzWxIwyVXP+7mogLoUNWZXTp+u0kyahe2SjcujpOZf9nd7zSl/rz5NTz/cJ1xl1aiutsbdb0JvsZxo+A4jpMDBtTS/CPy5saNguM4Tg4YxlLLNn0UM24UHMdxcqIljBR891GF0b33xlz39PnL0z2zR3LQz/Zl7fU68bv7zmT05Iv53X1n0nndjpllDtyvP6Nf+yNj/nM1h/zye2Xr1NT6LUlGDDrkISMGHWKSkQXDqLFsKWZatVGQVBPcAr8i6S5JHUP+gqJyR0m6RtI3JT1bCJgSAotMlrSbpK2UxHWdIuk1SaPqaHNMHW6IMzHrjQ/42e7n8rPdz+WkPc9jyaIvefrvL3Dw6d9i8uOvccwOZzH58dc45PRvNSwMqKqq4uRrjuWcAy7kp31P4xuH7s6m23TPrE9T67ckGTHo4P3IX0Y51GKZUkOEIEv/ljRN0quSfh7y15f0iKQ3wt/1Qr4kXSVphqSpknZMyToylH9D0pENtd2qjQIrop71Iwkgf0J9hc3sEZLANceGrJOBSWb2DHAVcEWQtw0hUlhWiiJMZaL/4D7MeesjPnpvHrt+awf+dWsSMvhftz7Frt/esYHaCVsN2oL3Z3zAB299xLKlyxh/x9PsduDAhivmVL8lyYhBB+9H/jKyYkANlillYBlwhpn1IYlBfaKkPiSBsR41s97Ao6wIlLU/SVzx3iQv6o2ExIgA55HE8B4EnFcwJHXR2o1CmidZNXBJKU4DzpbUFziJFUFJupGEpwTAzF4uUXclJL0t6RJJL5IEfimLwT/cmfF3TQBgvQ27MP/DTwGY/+GnrLdhQzHVE7pusj4fz1oRv33urPl03WSDemrkW78lyYhBhzxkxKBDTDLKIa+RgpnNMbMXw+fPgddIYrAfSBIQivC3MB92IDDWEiYA60rqRhJk6xEzm29mnwCPAPW+H+ELzYCkNiSW9qGQVQgUXmB9QphDM5sj6UqSqGOnmNn8UOYK4DFJzwD/BG4ys/9maH6ema3yWB98tRwHsJY6rVKpTdtqdjlgB0afd/cq54KeGZp2HCcvDFjaDL+7EP1vB+A5YKMQwRCSOOQbhc+bkISNLTAr5NWVXyetfaRQuPlPIglReWPIL0wr9Q+xYc8tqnctUG1mYwoZZnYTSYjGu0hiGE+QlOU1zjtKZZrZKDMbaGYDS72tvNO+2zFjyjv89+PPAPjk409Zf6NkdLD+Rl3479zPMjQNc2fPZ8PuK56cunZfn7mz59VTI9/6LUlGDDrkISMGHWKSkRXLOHUUpo+6SpqUSiV9M0nqTBLG9FQzW+lHHUKq5m6FWrtRSN/8TzazL7NUMrNaSnwZZva+mY02swNJ5gT7SbopLD6Pq0Nco141HvzDXRh/94TlxxPGTWGfw/YAYJ/D9uDZBydnkvP6xBls0rsbG/f8Cm3atmHwIbvz7P2TGq6YU/2WJCMGHbwf+cvIjEFNxgTMLTz0hbTKxhRJbUkMwq1mdk/I/jBMCxH+fhTyZwM9UtW7h7y68uvEp49yQtIQkgWgpZI2BjYAZpvZ0Xm31b5jO3bcqy9//PmY5Xl3XP4Av7r5RIYcvicfvTePC4+8LpOs2pparjn5Rn730K+oqq7i4Zv+zTvTZjVcMaf6LUlGDDp4P/KXkZXkjeZ8CDscbwReM7PLU6fuB44ELg5/70vlnyTpdpJF5U/DVPfDwEWpxeV9gbPrbbs1zz1LWmBmq3iaK86XdBQw0MxOqqfM5cC3gMUh61Izu6WE7DHAA2Z2t6S3g9y59enZpbqrue8jx2le/mV3v2Bmjd6atO127eyecdlcGm3ZY069bUnag2Tzy8ussDXnkKwr3AlsSrIT8mAzmx+MyDUki8hfAEeb2aQg65hQF+DCMNVdJ63aKFQKbhQcp/lpqlHot107u/PBbE5W+276fpPaak58+shxHCcHkvcUtKbVaDJuFBzHcXKi1twoOKsBq61t8vSP2rZrmg5LM23McpxWi48UHMdxnOUYoqYF7PJ3o+A4jpMTPn3kOI7jAMlI4Usr269ldFT+WKeV0xhf8W3bt+Wqp85n5MSLGDX5Eg7/zQ8A6P+Nvlw74QJGPn8Rlz92Lv/Ta6MGJDVeh5YqIwYd8pARgw4xychC8vJaVaYUM3Fr59RLY33FL12ylF/sdyHDdjqHYTudw077bsfWg7bglKuP5uKjrmPYoHP49x3P8OOzGv4BxeLzPgYZMejg/chfRjnUoEwpZtwoVDBN8RW/eOESIPG2Wt22GswwMzqt3QGATut0ZN6cT5pVh5YmIwYdvB/5y8iKmaixqkwpZuLWzqmXpviKr6oSI5+/iDtnjeTFR19h+sSZXHHCDVxw33BunXk1ex+2B3dc+vdm1aGlyYhBhzxkxKBDTDLKoRZlSjHjRqGVUltrDBt0Dj/e/GS2GtiLnn268/1T9ufXB17KYb1O5p9jH+f43x+2ptV0nIohWWhukynFjBuFCiYPX/ELP/2Clx6fxk5Dtmfz7TZl+sSZAIy/awJ9dt1ytejQUmTEoEMeMmLQISYZWfGFZmeN01hf8V26rk2nLh0BaLdWW3bcux/vTn+fTut0ZJPeGwMwYO9+vDu9XrfrTdKhJcqIQQfvR/4yyqHGlCnFTNzjGKdeGusrfv2N12X4jSdQVV1FVZV4/O7neG7cZK4cdgPn3n4qtbW1LPhkIZcdv0rcj9x0aIkyYtDB+5G/jKy0lDea3XV2BbCO1redtXeTZLjvI8epn6a6zu61bSe76N4+mcoe2nuSu852HMdpySQO8Sp/pOBGwXEcJwcMsdTdXDiO4zgAZuT28pqk0ZI+kvRKKu8OSVNCelvSlJDfU9Ki1LnrU3UGSHpZ0gxJV4WwnfXiIwXHcZxcyPXFtDEkMZfHFjLM7JDlLUmXAZ+mys80s/4l5IwE/pcktvM4khjO/6ivYTcKrYSmLhRXdezYZB1qv/iiyTIcJ1YMcnNhYWZPSOpZ6lx42j8Y2Ks+GZK6AeuY2YRwPBb4Hg0YBZ8+chzHyYkaqjKlJrIn8KGZvZHK20zSZEmPS9oz5G0CpPffzgp59eIjBcdxnBwwVE6Qna6S0m/RjTKzhl8MShgK/CV1PAfY1MzmSRoA/E1S36yKFONGwXEcJwcMWJrdr9HcxrynIKkN8H1gwPJ2zZYAS8LnFyTNBLYEZgNpP+HdQ169+PRRhbOmgpB06tKRX99yEje8+Dv+/MLv2GZQL/Y8aCdGTbyIf3x2E7136NnsOsQoIwYd8pARgw4xychGtlgKTYynsA8w3cyWTwtJ2lBSdfi8OdAbeNPM5gCfSdolrEMcAdzXUAPNZhQk1YTtUa9IuktSx9S570kySVun8tLbqqZJGiupraT9UlutFkh6PXweW9Te9oUtWuF4aJDXNhxvK2lq+Dxe0sCittNbv/aQ9Lyk6SEdlzo3QtKZ9fS3kM4qUWaldprKmgxCMuz3hzHpkZf56Y5nM2yXX/Pu63N4e9oszv/xVbz89OsV0488ZcSgg/cjfxlZMaDWqjKlhpD0F+BZYCtJsyQdG04dyspTRwBfA6aG+9/dwAlmNj+c+xlwAzADmEkDi8zQvCOFRWbW38z6AV8CJ6TODQWeCn/TFLZVbUsy1DnYzB4OcvoDk4DDwvERRXVfBjaVtHY43g14DdghdfxMQ0pL2hi4jeTCbg3sARwv6VsZ+1tIFzfUVqrNRk3jrakgJB3X6cC2u2/FQzc/DsCypTUs/PQL3nt9DrPe+KBi+pG3jBh08H7kL6Mc8hopmNlQM+tmZm3NrLuZ3RjyjzKz64vK/tXM+ob7zo5m9vfUuUlm1s/MepnZSZbBr9Hqmj56EtgCQFJnkhvtsSRWbxXMrAZ4ngwr5ak6tSRGY+eQNQC4lsQYEP4+nUHUicAYM3sxyJ0L/AJY5cm/KUg6StL9kh4DHm2MjDUVhGTjr27Ip3M/54zrf8q1T5/PqdccQ/uOjfetFEswFQ9OE48OMcnIiplyGymsSZpdu/AUvD/JkzzAgcBDZvYfoLBaXlxnLZKb+0NlNvc0sJukTkAtMJ6VjUJ6pHBrYaqH5KWOAn2BF4rkTgr59dGhaProkAbKA+wI/NDMvl58QtJxkiZJmrQ0WUOKhuo2VWzR/6s8cMNjnLj7uSz+YgmHnPHtNa2W46xRkoXm6kwpZprTKHQIN9xJwLvAjSF/KHB7+Hw7K08h9Qp1PgTmmNnUMtt8huTmPwiYaGYzgS0kbQh0DscFCtNQ/YEDymynFMXTR3dkqPNIau5vJcxslJkNNLOBbWlfsvKaCkIyd/YnfDx7Pq9PehOAp/42kS22/2pZ7TZVhxhlxKBDHjJi0CEmGdnxGM0Nkb5JnmxmX0pan+QtvBskvQ0MBw5O+eMorCn0AgZI+m59DUi6KTyVF570JwA7AbuTLNJA8sLGoanjhphGartXYADwasb6af12To0cSvVlYbky06ypICSffPQpc2fPp3sIyNN/cB/enf5+xfUjbxkx6OD9yF9GVpKFZmVKMbO631P4IfB/ZnZ8IUPS4yRv6L1byDOzuWH3ztnA/XUJM7Oji44/l/QecDQwOGQ/C5wKXJdRx2uB5yTdY2ZTJG0AXAKcn7F+Wp/ngOX+SOp6bb2xrMkgJNeecQu/vPEE2rRrwwdvfcRlw25gt+8M4Gd/+Alduq7Nb/96OjOnvsuvvveHqPuRp4wYdPB+5C+jHFqC6+xmC7IjaYGZdS7K+zdwiZk9lMo7BdiG5Mb7QNitVPDvMQU4ycyeDHnjgTPNrE5TL+la4EAz6x6OBwP/BnYzs2dLyQk363TbXwMuA9YGBFxpZiPDuREkRmZBoU0z6y6phhXrJpCsm6y0OJ1uR9JRwEAzO6muvhTII8hOU3HfR05Lp6lBdjbuu74dcVu23+ml/ZvWVnPikdcqADcKjtP85GEUfnLbNzOVvaz/ndEaBXdz4TiOkwNmsLS28qeP3Cg4juPkQOIQz42C00rIY+pHbRv/gluBpsaFcJzmpIl+jaLAjYLjOE4OFLakVjpuFBzHcXLBp48cx3GcFDnGaF5juFFwHMfJgWT3Udx+jbJQ+WOdVk4MQUgaU79t+7Zc9dT5jJx4EaMmX8Lhv/kBAP2/0ZdrJ1zAyOcv4vLHzuV/em202vqRh4wYdMhDRgw6xCQjC4VwnJXu5sKNQgUTQxCSxtZfumQpv9jvQobtdA7DdjqHnfbdjq0HbcEpVx/NxUddx7BB5/DvO57hx2dl+xFX8rWITUYMOsQkoxxqUaYUM24UKpgYgpA0pf7ihYlL8DZtq6luWw1mmBmd1u4AQKd1OjJvzierpR95yIhBB+9H/jKy0lIc4rlRqGBiCELSlPpVVWLk8xdx56yRvPjoK0yfOJMrTriBC+4bzq0zr2bvw/bgjkv/3rCgHPqRh4wYdMhDRgw6xCSjHHIMxzla0kdFYYJHSJqd8rx8QOrc2ZJmhHDF+6Xyh4S8GaVCBJfCjYKzxqitNYYNOocfb34yWw3sRc8+3fn+Kfvz6wMv5bBeJ/PPsY9z/O8PW9NqOk4mzMQyq8qUMjAGGFIi/4pUSIJxAJL6kIQH6BvqXCepWlI1idfn/YE+wNBQtl7cKFQwMQQhyUOHhZ9+wUuPT2OnIduz+XabMn1iEgtp/F0T6LPrlqtNjxiuRQwyYtAhJhnlkNf0kZk9AZQMwFWCA4HbzWyJmb0FzCAJNDYImGFmb5rZlyRBzQ5sSJgbhQomhiAkja3fpevadOqSeF5tt1Zbdty7H+9Of59O63RkkxC8Z8De/Xh3+uzV0o88ZMSgg/cjfxlZWU1rCidJmhqml9YLeZsA76XKzAp5deXXi7+nUMHEEISksfXX33hdht94AlXVVVRVicfvfo7nxk3mymE3cO7tp1JbW8uCTxZy2fGjVks/8pARgw7ej/xllNVe9ht+V0lp6zTKzBr6Zx8J/JbE/vyWJObLMWUr2QAeT6ECiCGeQh64QzwnZpoaT6HL1hvZHqMOyVR23NevbrCt4uBfdZ2TdDaAmf0unHsYGBGKjjCz/UL+SuXqwqePHMdxcqI531OQ1C11eBBQ2Jl0P3CopPaSNgN6A88DE4HekjaT1I5kMbrO8MYFfPrIcRwnB8xgWU5BdiT9hSTOfFdJs4DzgMGS+pNMH70NHJ+0a69KuhOYBiwDTjSzmiDnJOBhoBoYbWavNtS2GwXHcZycyOvFNDMbWiL7xnrKXwhcWCJ/HDCunLbdKDirDV8PcFoyBd9HlY4bBcdxnJwwNwqO4zhOgdid3WXBjYLjOE4OmLWMcJy+JbXCicHffAw6nHHjMO784AZGTb2sUe3npUcM1yIPGTHoEJOMbIia2qpMKWbi1q4OJNUEL4GvSLpLUsei/EI6K+SPD54CX5I0MWzrKiW3o6RbJb0cZD8lqXM4113SfZLekDRT0h/D3t9C3UGSngjtTJZ0Q0GvojbGS8rFd28M/uZj0AHgn2PGc87+q2y+WK16xHItvB/5yigHM2VKMVORRgFYFLwE9gO+BE4oyi+ki1N1DjOz7YHrgEvrkPtz4EMz2zbIPhZYKknAPcDfzKw3sCXQmbAFTNJGwF3AL81sKzPbAXgIWDtrh4JHw7KIwd98DDoAvPzka3w+f0FZdfLWI5Zr4f3IV0ZWPJ5CPDwJbFFG+Wep2ylUN2C5BzYze93MlgB7AYvN7KaQXwOcBhwTRgMnAjeb2bOpuneb2Yf1KSJpgaTLJL0E7FpGH4A4/M3HoENetJRr4f3IV0ZmLFlXyJJipqKNgqQ2JL7CXw5ZHYqmj0o5IhkC/K0OkaOBX0p6VtIFknqH/L7AC+mCZvYZ8C6JQepXfD4jnYDnzGx7M3uqEfUdx4mIlhCOs1J3H3WQNCV8fpIVb/otMrOS6wXArWENoDNQsoyZTZG0ObAvsA8wUVLZT/BlUAP8tdQJSccBxwGsxSpLE0Ac/uZj0CEvWsq18H7kKyMrFhaaK51K7UF67eDkEECiIQ4DNgduBq4GkHRQalQxEMDMFpjZPWb2M+AW4AASnyID0sIkrQNsShLQ4tXi86lyDwf5N5Q4vbjgo6QYMxtlZgPNbGBb2pfsUAz+5mPQIS9ayrXwfuQroxxawvRRpY4UGoWZmaTfADMlbW1m9wL3Fs5L2h2YZmafhFFFH2A88ChwsaQjzGxsWBS+DBhjZl9IugZ4XtKDZvZckPV94OmC29rmIAZ/8zHoAHDOrT9nu8F96dJ1bW5793rGjriTh0Y/tlr1iOVaeD/ylVEOse8sykJFxlOQtMDMOpfIr2HF+gLAQ2Z2lqTxwJlmNimUOwPoY2bHFtU/AjgTEMko6kGSHUUmqQfJzqWtw7lxQeaSUHdX4PfAV4Ba4AngNDP7oqiN5brU1Y9iWko8BceJmabGU+iwxf/YFpf/b6ayrxx4fpPaak4qcqRQ143UzEpu6zSzwUXHJd9wMrOxwNg6zr0HfKcenZ4F9qzrfCldshgEx3Eqh9i3m2ahIo2C4zhOjFTgxMsquFFwHMfJAUPUtoDdR24UHMdxcqIFDBQqdkuq4zhOXFh+vo8kjZb0kaRXUnmXSpouaaqkeyWtGzyqtHoAACAASURBVPJ7SlqU2l5/farOgODLbYakq4LLnnpxo+A4jpMXljE1zBgS7wtpHgH6mdl2wH+As1PnZqbe3TohlT8S+F+gd0jFMlfBjYLjOE5O5DVSMLMngPlFef80s2XhcAJQr7tXSd2AdcxsgiXvHowFGvQd7kbBcRwnBwyorVWmlAPHAP9IHW8WXPY/LqmwNX4TIP2m3izqdga6HDcKFU4MQUhi0CEPGXkE6omhH3nIiEGHmGRkwgBTtgRdJU1KpeOyNiPpV8Ay4NaQNQfYNLjsPx24LbjhaRRuFCqYGIKQxKBDXjKaGqgnln74d5qvjHIow/fR3IJvs5BGZZEv6Sjg2yTxYSxp05aY2bzw+QVgJknMl9msPMXUnVRogLpwo1DBxBCEJAYd8pLR1EA9sfTDv9N8ZZRFfgvNqyBpCPAL4Ltp9zmSNiwE6QpennsDb5rZHOAzSbuEXUdHAPc11I4bhQomhiAkMeiQl4ymEks//DvNV0Z2si0yZ9yS+heSgGBbSZol6VjgGpJojo8UbT39GjA1hBO4GzjBzAqL1D8DbiDx5jyTldchSuIvrzmO4+RFTm+vmdnQEtk3lsjDzP5KHXFZghPQfuW07UahgokhCEkMOuQlo6nE0g//TvOVkRkDy2dn0RrFp48qmBiCkMSgQ14ymkos/fDvNF8Z5aGMKV58pFDBxBCEJAYd8pLR1EA9sfTDv9N8ZZRFC3B+VJFBdlobHmTHcZqfpgbZab9Zd+t23smZyr5z9FkeZMdxHKdFU3h5rcJxo+A4jpMTLWHiJbNRkNS+EI/YcRzHKUFr2H0kaZCkl4E3wvH2kq5uds0cx3EqDFm2FDNZtqReReJro+Bb4yXgG82plOM4TsWR1cVF5EYhy/RRlZm9UxSwp6aZ9HEcx6lQ1GoWmt+TNAiw4HTpZJKoP47jOE6ayEcBWchiFIaRTCFtCnwI/CvkOY7jOGlq17QCTafBNQUz+8jMDjWzriEdamZzV4dyTsPEEIQkBh1ikdFSAvXEoENMMjJRXpCdaMmy++jPkkYVp9WhXD06dZd0n6Q3JM2U9EdJ7SQNlvRpcCs7XdIfiuoNkfR8ODdF0h2SNq2nne9JMklbp/J6SloU6hdSO0lHSfo4lTe2DpmNd9hfRAxBSGLQISYZLSFQTww6xCSjHFrL7qN/AY+G9DTwFWCNva8QgkXcA/zNzHqTRBjqDBR+iU+aWX9gB+DbknYP9foBVwNHmtnWocytQM96mhsKPBX+pplpZv1T6cuQf0cq74gy+tSolwhjCEISgw4xyWgJgXpi0CEmGWXRAnYfZZk+uiOVbga+DwxoftXqZC9gsZndFPSrAU4jCWTdsVDIzBYBU1gRqPqXwEVm9lqqzP1m9kSpRiR1BvYAjgUOzbsTYVTzpKT7gWmNkRFDEJIYdIhJRlOJoR8x6BCTjNZGY1xnbwZslLciZdAXeCGdYWafAe8CWxTyJK1HEpbuiVS9F8to50DgITP7DzBPUtoQ9kpNE12byj8klX90hjZ2BH5uZlsWn5B0XCGo99I1NzBzHKcMWsL0UYPTFpI+YcWApwqYD5zVnEo1kT0lvURiEK40sw+KC0jagGQ6rCMwysz+UFyGZMroj+Hz7eG4YIxmhumnYu4ws5PK0PV5M3ur1IkQyHsUJF5SS5WJIQhJDDrEJKOpxNCPGHSISUZmjJbv5iLM328PbBjSema2uZnduTqUq4NpFE1fSVqHZMvsDJI1he1JRgbHSircvF8leTLHzOaFm/oooLOkHqkn/BMkrU8yTXWDpLeB4cDBKnqDryGK5ZYosrAcecXEEIQkBh1iktFUYuhHDDrEJKMsclpTkDRa0keSXknlrS/pkbDB5pEwG4ISrpI0Q9JUSTum6hwZyr8h6cgsXah3pGBmJmmcmZUV47OZeRS4WNIRZjY2vFB3GTAG+KJQyMzeknQxyVrCUOD3wL2SJqTWFTqGsu8By5/8JR0H/J+ZHZ/KexzYk2SaKhPFcvMmhiAkMegQk4yWEKgnBh1iklEOOU4NjQGuAdK7GM8CHjWziyWdFY5/CexPMjPSG9gZGAnsHB5uzwMGkpiiFyTdb2af1N+HBny9SroFuMzMJjeiY82CpB7AdcDWJKOdccCZwK7AmWb27VCuA8noYXcze1vSt4ARwDrAXJIb/Hlh3SAt/9/AJWb2UCrvFGAb4BLggWJDKekoYGBD00eSFphZZ0mD07rWhwfZcZzmp8lBdnr0sO6nnpap7JtnntFgW5J6krrXSHodGGxmcyR1A8ab2VaS/hQ+/yVdrpAKD7fF5eqizpGCpDZmtoxka+dESTNJpjtEMojYsa66zU14Av9OiVPjQyqUW8SK3UeY2YPAgxnkr+Lwz8yuSh2uMnIyszEk1r0h2Z3D35V0dRynBZB9pNBVUnoea1RYR6yPjcxsTvj8ASs2/GwCvJcqNyvk1ZVfL/VNHz1PMgf/3YaEOI7jtHbK3Fk0tymjkjC13yz7mOozCgqNz2yOhh3HcVoczbv76ENJ3VLTRx+F/NlAj1S57iFvNskUUjp/fEON1GcUNpR0el0nzezyhoQ7jlMatW/fZBm2xN9fiY1mfgfhfuBI4OLw975U/kmSbidZaP40GI6HgYsKu5SAfYGzG2qkPqNQTeI+ovI33jqO46wOcjIKkv5C8pTfVdIskl1EFwN3SjoWeAc4OBQfBxxAsqnmC+BoADObL+m3wMRQ7nwzm99Q2/UZhTlmdn753XEcx2mF5Pi2spkV+1srsMo2REu2kJ5Yh5zRwOhy2m5wTcFxHMfJSOQuLLJQn1HwjfGO4zhloJYcZCfL3JOz5okhCEkMOsQioyn1q6rEdc9ewPl/PQOAy/71G0ZOuJCREy7kL29ezYg7T10teuRRv6XJaE00xkuqEwkxBCGJQYdYZDS1/kEnDeHd199ffnzGPr9l2C6/Ytguv2Lac2/w1N+y+exZ0/1oaTLKojXEU3DiJYYgJDHoEIuMptTvusn6DBrSn4duGr/KuY5rd6D/1/vyzN9fWLViZP1oiTIyk9Ftduyus90oVDAxBCGJQYdYZDSl/rBLf8INv/oLtbWr3jF2+84Apox/lS8+X9TseuRRv6XJKAsfKTiO01R23r8///3oM96Y/HbJ8984eFf+feezq1cpp3G0AKPQqNjAThzEEIQkBh1ikdHY+n133ZJdvr0jOw3Znnbt29JxnQ78cvQwLjlmJOts0JmtBm7OiEOujL4fLVVGVkQL333kxE8MQUhi0CEWGY2tP/rcOzlsi1M4YuvTuOiIa5kyfhqXHDMSgD0PGsRz/5jC0iVLo+9HS5WRmRaypuAjhQomhiAkMegQi4zmCOgy+Ee7cscf/l5WnRj60ZJklEXkN/wsNBhkx1nzeJCdloc7xIuPpgbZ6dCth212dJ0+RFfitd+d3qS2mhMfKTiO4+RE7FNDWXCj4DiOkxduFBzHcRwgWWhuAbuP3Cg4zhrA1wNaKD5ScBzHcQr4moLjOI6zghZgFPzlNcdxnDzI6uIig+GQtJWkKan0maRTJY2QNDuVf0CqztmSZkh6XdJ+je2GG4UKJwZ/8zHoEIuMGHRo274tV0/4HddPvpQ/v3w5R4w4uOFKOevQ0mRkQeT3RrOZvW5m/c2sPzCAJPbyveH0FYVzZjYOQFIf4FCgLzAEuE5SdWP64UahDiR9T5JJ2joc95S0KFjnaZLGSmorab+U1V4QrPQUSWNLyBwj6Yd56RiDv/kYdIhFRgw6ACxdspThe/8/TthhOCfsMJyB+/Vnm517V1w/YpFRDs3k5mJvYKaZvVNPmQOB281siZm9BcwABjWmD24U6mYo8FT4W2BmsNzbAt2Bg83s4ZRFnwQcFo6PyNpQYy16DP7mY9AhFhkx6FBg8cLFALRpW02bttWU47kgln7EIqMssk8fdZU0KZWOq0fqocBfUscnSZoqabSk9ULeJsB7qTKzQl7ZuFEogaTOwB7AsSRfyEqYWQ3wPI286KGNtyVdIulF4EeNkRGDv/kYdIhFRgw6FKiqquL6Fy/lrg9v5MV/TWX68zNWqw4tSUZZZDcKc81sYCqNKiVOUjvgu8BdIWsk0AvoD8wBLsu7C24USnMg8JCZ/QeYJ2lA+qSktYCdgYea2M48M9vRzG5vohzHWYna2lpO2HE4Q3scz1Y7bUHPvj3WtEotn+bxkro/8KKZfQhgZh+aWY2Z1QJ/ZsUU0Wwg/SV3D3ll40ahNEOBwo36dlZMIfWSNAX4EJhjZlOb2M4ddZ2QdFxhaLmU0i86xeBvPgYdYpERgw7FLPz0C14a/yoDh/RfrTq0JBllkX+QnaGkpo4kdUudOwh4JXy+HzhUUntJmwG9SWYzysaNQhGS1gf2Am6Q9DYwHDiYZHNBYU2hFzBA0ncbkHVTWHQeV0eRhXXVNbNRhaFlW0p71IzB33wMOsQiIwYdALp0XYdOXToC0G6tduy4z3a8Nz37Q2Ms/YhFRjmoNlvKJEvqBHwTuCeV/XtJL0uaCnwDOA3AzF4F7gSmkcxgnBimucvGX15blR8C/2dmxxcyJD1OamhmZnMlnQWcTWKhS2JmRzenojH4m49Bh1hkxKADwPrd1uUXY06iqroKVYkn7nqW5x58seL6EYuMcsjzjWYzWwhsUJR3eD3lLwQubGq7Hk+hCEn/Bi4xs4dSeaeQzO31MLN+IU/AFOAkM3sy5I0HzjSzko8iksYAD5jZ3WEUMtDM5jakk8dTcJzmp6nxFDpu2MO2/kG2eAqT/+TxFCoGM/tGibyrgKuK8gzYvihvcAOyj0p97tkENR3HiZEW8IztRsFxHCcHCm80VzpuFBzHcXJCtZVvFdwoOI7j5EH5202jxI2C47Ri1LZdk2XY0i9z0KRl4NNHjuM4zgrcKDiO4zgFfKTgOI7jrKAFGAV3c1HhxBCEJAYdYpERgw6NkdG2fVuueup8Rk68iFGTL+Hw3/wAgP6D+3DthAsY9eLFDL/heKqqs98yKvVaNBrL183FmsKNQgUTQxCSGHSIRUYMOjRWxtIlS/nFfhcybKdzGLbTOey073b02aU3w284gYsOv4bjdjyLD9+dy76H7xl1P5pDRlbyjLy2JnGjUMHEEIQkBh1ikRGDDk2RsXhh4o23TdtqqttWU1tTy9Kly5j9xgcAvPjoK+xxULZgXpV+LRqNWbYUMW4UKpgYgpDEoEMsMmLQoSkyqqrEyOcv4s5ZI3nx0VeYPnEm1dXV9N5xMwD2/P6gldxQx9qPvGWUQ0sYKfhCs+M4ANTWGsMGnUOnLh05787T6NmnOxcdfjUnXPoT2rZvy4v/epnamsgnxNck/vKas6aJIQhJDDrEIiMGHfKQsfDTL3jp8WkM3G877r5iHGfs/VsABuyzLZv03ni16BCTjHKIfRE5Cz59VMHEEIQkBh1ikRGDDo2V0aXr2qnAPG3Zce9+vPf6HNbdcB0A2rZrw8FnfpsH//xo1P1oDhnl0BJ2H/lIoYKJIQhJDDrEIiMGHRorY/2N12X4jSdQVV1FVZV4/O7neG7cZP73d0PZ+YAdUJV4YNSjTBk/Lep+NIeMzBjRLyJnwYPsVAAeZMdpLtz30QqaGmSn83o9rP9eP89U9ul7hjfYVgjE9TlQAywzs4EhXPAdQE/gbeBgM/skBP36I3AA8AVwlJllD7eXwqePHMdx8sIypux8w8z6pwzIWcCjZtYbeDQcQxIZsndIxwEjG9sFNwqO4zg5sJpeXjsQuDl8vhn4Xip/rCVMANaV1K0xDbhRcBzHyQMzVJstAV0lTUql40pJBP4p6YXU+Y3MbE74/AGwUfi8CfBequ6skFc2vtDsOI6TF9lHAXMzrF/sYWazJX0FeETS9JWaMjMp/1fh3Cg4TiumpSwSx0Ket2gzmx3+fiTpXmAQ8KGkbmY2J0wPfRSKzwZ6pKp3D3ll49NHjuM4eWBArWVLDSCpk6S1C5+BfYFXgPuBI0OxI4H7wuf7gSOUsAvwaWqaqSx8pOA4jpMX+Y0UNgLuTXaa0ga4zcwekjQRuFPSscA7wMGh/DiS7agzSLakHt3Yht0oOI7j5ERe00dm9iawfYn8ecAqLy1Z8sLZiXm07dNHFU4MQUhi0CEWGTHokIeMPHTo1KUjv7nzDG6cdiU3vnoF2+yy5RrRY7UF2YFydh9FS0UaBUkbSbpN0pthu9azkg6SNFjSp5KmpNI+oY5Juiwl40xJI+ppo3+oM6Qov6ZIfs8S7f6rDplvS+qa02WIIghJDDrEIiMGHWLpB8DPrjyaSQ9P5tg+p3J8/+G8+1p57iViuBZlkfXFtbhtQuUZhfA699+AJ8xsczMbABxKstoO8GR4A7CQCjfoJcD3y7gpDwWeCn/TLCqS/3aJdvcppz+SGvU9xBCEJAYdYpERgw6x9KPjOh3Z9mt9+MeNjwGwbOkyFn76xWrtR14yspK8vGaZUsxUnFEA9gK+NLPrCxlm9o6ZXd1AvWXAKOC0hhoIhudHwFHANyWt1Xh1S8rvKel1SWNJdhT0aKhOKWIIQhKDDrHIiEGHPGTkoUO3zb7Cpx9/xvDRJzLyhd9z+p9PYK2O7cuSEcO1KJvajCliKtEo9AXqc/S0Z9H0Tq/UuWuBwyR1aaCN3YC3zGwmMB74Vupch5Tse+to91cZ+tEbuM7M+prZO8UnJR1XeNtxKUsyiHOceKhuU0XvHTfj79c/zLABv2DxwiUcclbzzufHQEsYKVT87iNJ1wJ7AF8Cw0mmcb5dqqyZfRaezk8BFtUjdihwe/h8O3AE8NdwvMjM+peoU2e7dfBO8FFSEjMbRTKyYR2tX/K/KIYgJDHoEIuMGHTIQ0YeOnw8az4fz5rH9OdnAPDE3c9y6C8PKktGDNeiLCpgvSALlThSeBXYsXBgZieSbNHaMGP9K4FjgU4AkqpTT/jnS6oGfgCcG1zXXg0MKbxIkpViuSWKLCxHXiliCEISgw6xyIhBh1j68cmH/+Xj9+bRfcv/AWCHvbflnTIXmmO4FuVRlu+jaKnEkcJjwEWShplZwT1sx6yVzWy+pDtJDMNoM6sBlj/5S9oXmGpm+6XybgYOAsaW0c5KcpuDGIKQxKBDLDJi0CGWfgBce8pozr7lFNq0a8OcNz/kD8dcV1b9GK5F2UQ+NZSFigyyE3x+XAHsDHxM8tR9PfAhyWvfb6WKX2Bmd0taYGadQ/2NQpnfm9mIItk3Ac+lF7IlfRcYZmb7p+Wkzg8Gzmxo+iiMPAYCnYEHzKxflv56kB3HaX6aGmRnnc6b2M79f5atrad/3aS2mpNKHCkQfHocWsfpkovI6Ru5mX1IHaMLM1vl9XAzu5/EtwjFBiHkjSdZkK4XM+sZPs4FMhkEx3EqiAp8yC6mIo2C4zhOlFS+TXCj4DiOkxeqjfwlhAy4UXAcx8kDI/oX07LgRsFxHCcHRPwvpmXBjYLjOE5euFFwHMdxluNGwXEcxwFazJpCJbq5cFLEEIQkBh1ikRGDDnnIiEGHM24cxp0f3MCoqZc1XLgZ9SgH1dZmSg3KkXpI+rekaZJelfTzkD9C0uyUC50DUnXOljQjeGDer27p9eNGoYKJIQhJDDrEIiMGHVpSP/45Zjzn7H9hWXWaQ4/sWDJ9lCU1zDLgDDPrA+wCnCipTzh3RSp2yziAcO5QEi/SQ4Drgh+3snGjUMHEEIQkBh1ikRGDDi2pHy8/+Rqfz19QVp3m0CMzRm5GwczmmNmL4fPnwGvAJvVUORC43cyWmNlbwAxgUGO64UahgokhCEkMOsQiIwYd8pARgw55EXGQna6FeCkhHVeXSEk9gR2A50LWSZKmShotab2QtwnwXqraLOo3InXiRsFxHCcnygiyM9fMBqbSqJLypM4ksVxONbPPgJFALxIPzHOApi24lMB3H1UwMQQhiUGHWGTEoEMeMmLQIS9Wux45bkmV1JbEINxqZvck4u3D1Pk/Aw+Ew9msHNa3e8grGx8pVDAxBCGJQYdYZMSgQ0vqRx6sVj3MoKY2W2qAECf+RuA1M7s8ld8tVewgkhjvkHhxPlRSe0mbkYT7fb4x3fCRQgUTQxCSGHSIRUYMOrSkfpxz68/ZbnBfunRdm9vevZ6xI+7kodGPrXY9yiK/kcLuwOHAy5KmhLxzgKGS+pMsa78NHJ80a6+G4GHTSHYunRgCfZVNRQbZaW14kB3HaX6aGmSny1ob227dD89U9qGZf/AgO47jOC0aAyKPv5wFNwqO4zi5YGCV7+fCjYLjOE4eGJkWkWPHjYLjOBXPw+9PabhQA1R3a7hMg7SANVo3Co7jOHnhRsFxHMdJyOzsLmrcKDiO4+SBARncYseOv9Fc4cTg9z4GHWKREYMOeciIQYf6ZGzYfQMuffQ8bnjlCv788uXQ8cjkhLqg9cagro+g9caA1gn5ndG6f0Ib3I82GAcdfrBcljr/Am0wjpkzZ/YFrgLUKGUhT9fZa4xWbRQk1YRAFa9IuktSx5C/oKjcUZKukfRNSc+GV9CRVC1psqTdJG0laXyQ95qkkg6uSugwQtKZjdE/Br/3MegQi4wYdGgt/ahZVsOfzhzLT/udxim7noM6HgbVW6BOx2NfPoPN/Sb25TOo0/GJsI4/gWUzsHnfxeb/BK19FtAW2u4A7XbE5n2bLbfc8lVgJ+DrZSm6nPzcXKxJWrVRABaFQBX9gC+BE+orbGaPAO8Ax4ask4FJZvYMyRNGIfjFNsDVDTUuqUnTdzH4vY9Bh1hkxKBDa+nH/A/+y4zJbwGwaMFiWDYTqjeCtfaGRfcmAhbdC2vtE6QZVHVKPlZ1hNpPSbxBGKg90JYOHTpUAW2BD2kMBma1mVLMtHajkOZJYIsM5U4DzpbUFzgJ+GXI70biwxwAM3u5VOUwmrhS0iTg501ROAa/9zHoEIuMGHTIQ0YMOpQjY6Ovbght+8DSl6CqK9R+nJyo/Tg5BvjiFqjuhTZ8Gm3wAPb5BYDB0inw5QT0lWd4//33twMeJglo0zhqLVuKGDcKLH9i3x8o3Mg7pGKgTgHOL5Q1sznAlcCzwAVmNj+cugJ4TNI/JJ0mad16mmwXfKjX6Qtd0nGFABxLWdKU7jlOi2WtTmtx7t1nYp9dCFYqSlu4AbfbE5a9hn28Ozbvu2jtc0GdoXpTqN4C+3hPunfvPhXYC9iz0Qr5mkLF0yHc9CcB75K4qoUV00r9zaw/cG5RvWuBajMbU8gws5uAbYC7gMHABEnt62j3joYUM7NRhQAcbSktJga/9zHoEIuMGHTIQ0YMOmSRUd2mmvPuPoPHbnsSlvwzyaydC1UbJp+rNoTapLw6/ABbHMrUvAs1s6DN5tB+X2zpFLAv+Oyzz2qBfwC7lqVoAbNk91GWFDGt3Sikb/4nm9mXWSpZMim4irk3s/fNbLSZHUgyYdlP0k1hxDEuVXRhHsrH4Pc+Bh1ikRGDDq2pH2fcMIx3p8/mr1c8sKLSksegw0HJ5w4HweJHk8+176P24V5ftQG02QyWvZfkt9sJqKZdu3YiWWRu/PRRCxgp+HsKOSFpCPComS2VtDGwATDbzI5urjZj8Hsfgw6xyIhBh9bSj767b803j/g6b059h+tfvBRtsAj7/DJswZ/Qun+EDj+CmtnYf5NlO1twLepyCdrgAUDY55eCfQKLH4J2u6KuDzJtGn1Iwl3+vSxFl2NYTaNCGERFq46nIGmBmXVuKF/SUcBAMzupnjKXA98CFoesS83slhKyxwNnmtmkcDwCWGBmf6hLT4+n4Dj1k4/voxlNi6dQtYHt0v6ATGX/ufgWj6cQI6UMQqn8sHYwpoEypwOnZ2hzcNHxiCy6Oo5TAUS+3TQLrX1NwXEcJxcMsFrLlLIgaYik1yXNkHRW82q/AjcKjuM4eWAhyE6W1ACSqkl2Oe4P9CGJzdynmXsAtPLpI8dxnDzJcaF5EDDDzN4EkHQ7cCAwLa8G6qJVLzRXCpI+JnGvURddgbmrSZ36iEGPGHSAOPSIQQeIQ48sOnzVzDZsbAOSHgrtZGEtVmxKARhlZsv9pUn6ITDEzH4ajg8Hdk5vdmkufKRQATT0jyppUgw7GWLQIwYdYtEjBh1i0WN16GBmQ5pT/urC1xQcx3HiYzbQI3XcPeQ1O24UHMdx4mMi0FvSZpLaAYcC96+Ohn36qGWQKXbDaiAGPWLQAeLQIwYdIA49YtAhM2a2TNJJJF5bq4HRZvbq6mjbF5qdVoukGhLPuG1I/N0caWZfNFLWYJI31b8t6btAHzO7uI6y6wI/NrPrymxjBA28/e44TcWnj5zWTL1BlpRQ9m/EzO6vyyAE1gV+Vq5cx1kduFFwnIQngS0k9QxvkY4FXgF6SNo3hGF9MYRt7QzL3zidLulF4PsFQYXwreHzRpLulfRSSLsBFwO9gvfcS0O54ZImSpoq6f+lZP1K0n8kPQVstdquhtNq8TUFp9WTCrL0UMjqTTKVNEFSV+DXwD5mtlDSL4HTJf0e+DNJUJYZ1B0j4yrgcTM7KLyl2hk4C+gXYnUgad/Q5iCSoPH3S/oaiYv1Q4H+JL/VF4EX8u2946yMGwWnNVMIsgTJSOFG4H+Ad8xsQsjfhcTNwNOSANqRRN3bGnjLzN4AkHQLcFyJNvYCjgAwsxrgU0nrFZXZN6TJ4bgziZFYG7i3sM4habXsPnFaN24UnNbMosLTeoFw408HQRLwiJkNLSq3Ur0mIuB3ZvanojZOzbENx8mEryk4Tv1MAHaXtAWApE6StgSmAz0l9QrlhtZR/1FgWKhbLakL8DnJKKDAw8AxqbWKTSR9BXgC+J6kDpLWBr6Tc98cZxXcKDhOPZjZx8BRwF8kTSVMHZnZYpLpogfDQvNHdYj4OfANSS+TrAf0MbN5JNNRr0i61Mz+CdwGPBvK3Q2sbWYvkqxVvEQSO3his3XUcQL+noLjOI6zHB8pOI7jOMtxo+A4juMsx42C4ziOsxw3Co7jOM5y3Cg4MitS/gAAABlJREFUjuM4y3Gj4DiO4yzHjYLjOI6znP8PwaWPDOGB0VgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plot_comfusion_matrix(label_types, predict_types, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/80 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 16/80 [00:00<00:00, 156.64it/s]\u001b[A\n",
      " 44%|████▍     | 35/80 [00:00<00:00, 164.99it/s]\u001b[A\n",
      " 61%|██████▏   | 49/80 [00:00<00:00, 154.11it/s]\u001b[A\n",
      " 76%|███████▋  | 61/80 [00:00<00:00, 132.04it/s]\u001b[A\n",
      " 98%|█████████▊| 78/80 [00:00<00:00, 138.26it/s]\u001b[A\n",
      "1861it [00:10, 173.46it/s]:00<00:00, 138.52it/s]\u001b[A\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-53e6287d8559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mUSE_GPU\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mlabel_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr_idx2label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d9fdcabd525a>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, ds)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_generator_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d9fdcabd525a>\u001b[0m in \u001b[0;36m_extract_data\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mout_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtonp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class_logits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-51b8bc8a3040>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens, arg_idx, label)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"class_logits\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclass_logits\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 942\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected 2 or more dimensions (got {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[1;32m   1869\u001b[0m                          .format(input.size(0), target.size(0)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "    # testing data analysis\n",
    "    \n",
    "    # AllenNLP DatasetReader\n",
    "    reader = RelationDatasetReader(\n",
    "        is_training=False, \n",
    "        ace05_reader=ace05_reader, \n",
    "        tokenizer=lambda s: token_indexer.wordpiece_tokenizer(s),\n",
    "        token_indexers={\"tokens\": token_indexer}\n",
    "    )\n",
    "    \n",
    "    test_ds = reader.read(test_path)\n",
    "    \n",
    "    seq_iterator = BasicIterator(batch_size=config.batch_size)\n",
    "    seq_iterator.index_with(vocab)\n",
    "    \n",
    "    predictor = Predictor(model, seq_iterator, cuda_device=0 if USE_GPU else -1)\n",
    "    test_preds = predictor.predict(test_ds) \n",
    "    \n",
    "    label_types = [r_idx2label.get(i.fields['label'].label) for i in test_ds]\n",
    "    predict_types = [r_idx2label.get(i) for i in np.argmax(test_preds, axis=-1)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    plot_comfusion_matrix(label_types, predict_types, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
